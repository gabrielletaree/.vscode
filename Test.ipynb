{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class IDs changed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def change_class_id(yolo_file_path):\n",
    "    with open(yolo_file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(yolo_file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 5:\n",
    "                # Change the class ID (assuming it is the first value in each line)\n",
    "                parts[0] = '1'\n",
    "                new_line = ' '.join(parts) + '\\n'\n",
    "                file.write(new_line)\n",
    "            else:\n",
    "                # If the line does not have enough values, write it as is\n",
    "                file.write(line)\n",
    "\n",
    "# Specify the path to the folder containing YOLO files\n",
    "yolo_folder = \"D:\\kuliah\\Magang_Winteq\\Project\\Data Baru dengan Annotations\\Cap\\Cap_Annotations_YOLOv5\"\n",
    "\n",
    "# Iterate through YOLO files in the folder and change class ID\n",
    "for yolo_file in os.listdir(yolo_folder):\n",
    "    if yolo_file.endswith(\".txt\"):\n",
    "        yolo_path = os.path.join(yolo_folder, yolo_file)\n",
    "        change_class_id(yolo_path)\n",
    "\n",
    "print(\"Class IDs changed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_xml_to_txt(xml_file, txt_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(txt_file, 'w') as txt_file:\n",
    "        for elem in root.iter():\n",
    "            # Extract relevant information and write to the text file\n",
    "            if elem.text:\n",
    "                txt_file.write(elem.text + '\\n')\n",
    "\n",
    "# Specify the path to the folder containing XML files\n",
    "xml_folder = r\"D:\\kuliah\\Magang_Winteq\\Project\\Nitip\"\n",
    "\n",
    "# Specify the path to the folder where TXT files will be saved\n",
    "txt_folder = r\"D:\\kuliah\\Magang_Winteq\\Project\\Nitip2\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(txt_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through XML files in the folder and convert each to TXT\n",
    "for xml_file in os.listdir(xml_folder):\n",
    "    if xml_file.endswith(\".xml\"):\n",
    "        xml_path = os.path.join(xml_folder, xml_file)\n",
    "        txt_file = os.path.join(txt_folder, os.path.splitext(xml_file)[0] + \".txt\")\n",
    "        convert_xml_to_txt(xml_path, txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_xml_to_yolo(xml_file, yolo_file, class_mapping):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    with open(yolo_file, 'w') as yolo_file:\n",
    "        for obj in root.iter('object'):\n",
    "            class_name = obj.find('name').text\n",
    "\n",
    "            # Check if class_name exists in the class_mapping dictionary\n",
    "            if class_name not in class_mapping:\n",
    "                print(f\"Warning: Unknown class '{class_name}'. Skipping...\")\n",
    "                continue\n",
    "\n",
    "            class_id = class_mapping[class_name]\n",
    "\n",
    "            bndbox = obj.find('bndbox')\n",
    "            xmin = float(bndbox.find('xmin').text)\n",
    "            ymin = float(bndbox.find('ymin').text)\n",
    "            xmax = float(bndbox.find('xmax').text)\n",
    "            ymax = float(bndbox.find('ymax').text)\n",
    "\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "            center_x = xmin + width / 2\n",
    "            center_y = ymin + height / 2\n",
    "\n",
    "            # Normalize coordinates\n",
    "            image_width = float(root.find('size').find('width').text)\n",
    "            image_height = float(root.find('size').find('height').text)\n",
    "\n",
    "            center_x /= image_width\n",
    "            center_y /= image_height\n",
    "            width /= image_width\n",
    "            height /= image_height\n",
    "\n",
    "            yolo_file.write(f\"{class_id} {center_x} {center_y} {width} {height}\\n\")\n",
    "\n",
    "# Specify the path to the folder containing XML files\n",
    "xml_folder = r\"D:\\kuliah\\Magang_Winteq\\Project\\Nitip\"\n",
    "\n",
    "# Specify the path to the folder where YOLO files will be saved\n",
    "yolo_folder = r\"D:\\kuliah\\Magang_Winteq\\Project\\Nitip2\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(yolo_folder, exist_ok=True)\n",
    "\n",
    "# Class mapping (replace with your own class names and IDs)\n",
    "class_mapping = {\"helmet\": 0}\n",
    "\n",
    "# Iterate through XML files in the folder and convert each to YOLO format\n",
    "for xml_file in os.listdir(xml_folder):\n",
    "    if xml_file.endswith(\".xml\"):\n",
    "        xml_path = os.path.join(xml_folder, xml_file)\n",
    "        yolo_file = os.path.join(yolo_folder, os.path.splitext(xml_file)[0] + \".txt\")\n",
    "        convert_xml_to_yolo(xml_path, yolo_file, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import math\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "data_dir = \"D:\\\\kuliah\\\\Magang_Winteq\\\\Project\\\\dataV2\"\n",
    "\n",
    "# Define valid image extensions\n",
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check image validity\n",
    "def is_valid_image(img_path):\n",
    "    try:\n",
    "        # Try to read the image using OpenCV\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            return False\n",
    "        # Check image file format using imghdr\n",
    "        tip = imghdr.what(img_path)\n",
    "        return tip in image_exts\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Clean the data directory\n",
    "for image_class in os.listdir(data_dir):\n",
    "    class_dir = os.path.join(data_dir, image_class)\n",
    "    for image in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image)\n",
    "        if not is_valid_image(image_path):\n",
    "            print(f'Removing invalid image: {image_path}')\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2716 files belonging to 2 classes.\n",
      "Using 2173 files for training.\n",
      "Found 2716 files belonging to 2 classes.\n",
      "Using 543 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.Resizing(img_height, img_width),  # Resize with a slight increase in size\n",
    "    tf.keras.layers.Rescaling(1./255),  # Rescale pixel values to [0,1]\n",
    "])\n",
    "\n",
    "# Load and preprocess training data with data augmentation\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Load validation data\n",
    "val_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Split validation data into validation and test sets\n",
    "val_ds = val_test_ds.take(len(val_test_ds) // 2)\n",
    "test_ds = val_test_ds.skip(len(val_test_ds) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 [==============================] - 59s 821ms/step - loss: 55.0914 - accuracy: 0.6673 - val_loss: 0.4997 - val_accuracy: 0.7344\n",
      "Epoch 2/20\n",
      "68/68 [==============================] - 57s 833ms/step - loss: 0.4544 - accuracy: 0.7671 - val_loss: 0.4411 - val_accuracy: 0.7891\n",
      "Epoch 3/20\n",
      "68/68 [==============================] - 55s 803ms/step - loss: 0.4134 - accuracy: 0.8030 - val_loss: 0.4623 - val_accuracy: 0.8203\n",
      "Epoch 4/20\n",
      "68/68 [==============================] - 57s 818ms/step - loss: 0.3459 - accuracy: 0.8389 - val_loss: 0.5261 - val_accuracy: 0.8086\n",
      "Epoch 5/20\n",
      "68/68 [==============================] - 55s 804ms/step - loss: 0.2883 - accuracy: 0.8656 - val_loss: 0.4846 - val_accuracy: 0.7930\n",
      "Epoch 6/20\n",
      "68/68 [==============================] - 56s 814ms/step - loss: 0.3107 - accuracy: 0.8601 - val_loss: 0.5579 - val_accuracy: 0.8281\n",
      "Epoch 7/20\n",
      "68/68 [==============================] - 55s 799ms/step - loss: 0.3211 - accuracy: 0.8670 - val_loss: 0.8006 - val_accuracy: 0.8164\n",
      "Epoch 8/20\n",
      "68/68 [==============================] - 56s 817ms/step - loss: 0.2087 - accuracy: 0.9172 - val_loss: 0.3880 - val_accuracy: 0.8945\n",
      "Epoch 9/20\n",
      "68/68 [==============================] - 60s 872ms/step - loss: 0.1574 - accuracy: 0.9370 - val_loss: 0.4173 - val_accuracy: 0.8906\n",
      "Epoch 10/20\n",
      "68/68 [==============================] - 55s 789ms/step - loss: 0.1298 - accuracy: 0.9512 - val_loss: 0.3152 - val_accuracy: 0.8984\n",
      "Epoch 11/20\n",
      "68/68 [==============================] - 54s 787ms/step - loss: 0.0770 - accuracy: 0.9682 - val_loss: 0.5924 - val_accuracy: 0.8828\n",
      "Epoch 12/20\n",
      "68/68 [==============================] - 75s 1s/step - loss: 0.0686 - accuracy: 0.9738 - val_loss: 0.6673 - val_accuracy: 0.8984\n",
      "Epoch 13/20\n",
      "68/68 [==============================] - 90s 1s/step - loss: 0.0645 - accuracy: 0.9807 - val_loss: 0.3942 - val_accuracy: 0.9023\n",
      "Epoch 14/20\n",
      "68/68 [==============================] - 93s 1s/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.5113 - val_accuracy: 0.9023\n",
      "Epoch 15/20\n",
      "68/68 [==============================] - 90s 1s/step - loss: 0.0887 - accuracy: 0.9673 - val_loss: 0.7787 - val_accuracy: 0.8867\n",
      "Epoch 16/20\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0621 - accuracy: 0.9738 - val_loss: 0.9018 - val_accuracy: 0.9062\n",
      "Epoch 17/20\n",
      "68/68 [==============================] - 89s 1s/step - loss: 0.0589 - accuracy: 0.9834 - val_loss: 0.8321 - val_accuracy: 0.9023\n",
      "Epoch 18/20\n",
      "68/68 [==============================] - 88s 1s/step - loss: 0.0510 - accuracy: 0.9788 - val_loss: 0.4844 - val_accuracy: 0.9102\n",
      "Epoch 19/20\n",
      "68/68 [==============================] - 98s 1s/step - loss: 0.0275 - accuracy: 0.9903 - val_loss: 0.8154 - val_accuracy: 0.9023\n",
      "Epoch 20/20\n",
      "68/68 [==============================] - 98s 1s/step - loss: 0.0266 - accuracy: 0.9940 - val_loss: 0.5567 - val_accuracy: 0.8828\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "num_classes = len(train_ds.class_names)\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model training\n",
    "epochs = 20\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 313ms/step - loss: 1.1363 - accuracy: 0.8676\n",
      "Test Accuracy: 86.76%\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Fungsi untuk mendeteksi dan menampilkan kotak pada objek menggunakan model\n",
    "def detect_and_display(frame, model, class_names):\n",
    "    # Praproses frame\n",
    "    resized_frame = cv2.resize(frame, (img_width, img_height))\n",
    "    input_data = np.expand_dims(resized_frame, axis=0) / 255.0\n",
    "\n",
    "    # Prediksi menggunakan model\n",
    "    predictions = model.predict(input_data)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    class_index = np.argmax(score)\n",
    "    confidence = 100 * np.max(score)\n",
    "\n",
    "    # Jika kepercayaan (confidence) lebih dari batas tertentu, tampilkan kotak dan label\n",
    "    if confidence > 75:\n",
    "        label = class_names[class_index]\n",
    "\n",
    "        # Koordinat kotak\n",
    "        box_color = (0, 255, 0)  # Warna hijau\n",
    "        box_thickness = 2\n",
    "\n",
    "        # Ambil ukuran frame\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        # Ambil koordinat kotak hasil prediksi\n",
    "        xmin = int(predictions[0][0] * width)\n",
    "        ymin = int(predictions[0][1] * height)\n",
    "        xmax = int(predictions[0][2] * width)\n",
    "        ymax = int(predictions[0][3] * height)\n",
    "\n",
    "        # Gambar kotak pada frame\n",
    "        cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), box_color, box_thickness)\n",
    "\n",
    "        # Tambahkan label pada kotak\n",
    "        label_position = (xmin, ymin - 10)  # Sedikit di atas kotak\n",
    "        cv2.putText(frame, f'{label} ({confidence:.2f}%)', label_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Fungsi untuk membaca video dari kamera\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)  # 0 untuk kamera bawaan\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Deteksi dan tampilkan hasil pada frame\n",
    "        frame_with_detection = detect_and_display(frame, model, class_names)\n",
    "\n",
    "        # Tampilkan frame\n",
    "        cv2.imshow('Safety Helmet and Cap Detection', frame_with_detection)\n",
    "\n",
    "        # Hentikan aplikasi jika tombol 'q' ditekan\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Tutup video stream dan jendela OpenCV\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Panggil fungsi main\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test dataset: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path ke folder test cap\n",
    "test_cap_path = \"D:\\kuliah\\Magang_Winteq\\Project\\cap_valid\"\n",
    "\n",
    "# Inisialisasi variabel\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterasi melalui gambar-gambar di folder test\n",
    "for filename in os.listdir(test_cap_path):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Path lengkap ke gambar\n",
    "        img_path = os.path.join(test_cap_path, filename)\n",
    "\n",
    "        # Load dan preprocess gambar\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = tf.expand_dims(img_array, 0)  # Tambahkan dimensi batch\n",
    "        img_array /= 255.0  # Normalisasi\n",
    "\n",
    "        # Prediksi menggunakan model\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "        # Cek apakah prediksi benar\n",
    "        true_class = 0  # Ganti dengan indeks kelas \"cap\"\n",
    "        if predicted_class == true_class:\n",
    "            correct_predictions += 1\n",
    "\n",
    "        total_predictions += 1\n",
    "\n",
    "# Hitung akurasi\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy on test dataset: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YOLO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
